{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsM2EN-GixcE",
        "outputId": "c860b954-aa70-4f4d-c7cf-b4e4ba7cdb39"
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "zpLA9ht2th5o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import os\n",
        "from collections import defaultdict, Counter\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "from scipy.stats import halfnorm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "vsfTYgclwjkT"
      },
      "outputs": [],
      "source": [
        "conditions_df = pd.read_csv('data/conditions.csv')\n",
        "medications_df = pd.read_csv('data/medications.csv')\n",
        "procedures_df = pd.read_csv('data/procedures.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "zeK2zXvUwsSC"
      },
      "outputs": [],
      "source": [
        "#map conditions (SNOMED) to diagnoses (ICD-10)\n",
        "snomed_to_icd = pd.read_csv('data/snomed_icd_10_map.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "5rpVDwipdOzc"
      },
      "outputs": [],
      "source": [
        "diagnoses_df = conditions_df.merge(snomed_to_icd, left_on='CODE', right_on='SNOMED ID', how='left')\n",
        "\n",
        "#filter out rows where no mapping was found (ICD ID = \"\\N\")\n",
        "diagnoses_df = diagnoses_df[diagnoses_df['ICD ID'] != '\\\\N']\n",
        "\n",
        "#strip all '?' characters from ICD ID column\n",
        "diagnoses_df['ICD ID'] = diagnoses_df['ICD ID'].str.replace('?', '')\n",
        "diagnoses_df = diagnoses_df[['START', 'STOP', 'PATIENT', \"ENCOUNTER\", \"CODE\", \"DESCRIPTION\", \"SNOMED ID\", \"ICD ID\", \"ICD Name\"]]\n",
        "\n",
        "#filter out rows of procedures_df where code = 428191000124101\n",
        "procedures_df = procedures_df[procedures_df['CODE'] != 428191000124101]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Kejr8P0f0pOQ"
      },
      "outputs": [],
      "source": [
        "#create patient_visits\n",
        "diagnoses_df['START'] = pd.to_datetime(diagnoses_df['START'])\n",
        "medications_df['START'] = pd.to_datetime(medications_df['START'])\n",
        "procedures_df['DATE'] = pd.to_datetime(procedures_df['DATE'])\n",
        "\n",
        "# Diagnosis: Use ICD ID\n",
        "diag_visits = diagnoses_df[['PATIENT', 'START', 'ICD ID']].copy()\n",
        "diag_visits.columns = ['PATIENT', 'DATE', 'CODE']\n",
        "diag_visits['CODE_TYPE'] = 'diagnosis'\n",
        "\n",
        "# Medication: Use RxNorm CODE\n",
        "med_visits = medications_df[['PATIENT', 'START', 'CODE']].copy()\n",
        "med_visits.columns = ['PATIENT', 'DATE', 'CODE']\n",
        "med_visits['CODE_TYPE'] = 'medication'\n",
        "\n",
        "# Procedures: Use HCPCS CODE\n",
        "proc_visits = procedures_df[['PATIENT', 'DATE', 'CODE']].copy()\n",
        "proc_visits['CODE_TYPE'] = 'procedure'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "s3LhTf4D0z2C"
      },
      "outputs": [],
      "source": [
        "combined_visits = pd.concat([diag_visits, med_visits, proc_visits], ignore_index=True)\n",
        "combined_visits = combined_visits.sort_values(by=['PATIENT', 'DATE'])\n",
        "\n",
        "patients_visits = defaultdict(list)\n",
        "#filter out rows where CODE is nan\n",
        "for _, row in combined_visits.iterrows():\n",
        "  if not pd.isna(row['CODE']):\n",
        "    patient = row['PATIENT']\n",
        "    entry = (row['DATE'], row['CODE'], row['CODE_TYPE'])\n",
        "    patients_visits[patient].append(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH_IpFE19XXF",
        "outputId": "5f80f234-6a89-4c8b-fa43-3c68a4e8d888"
      },
      "outputs": [],
      "source": [
        "#create (context_window, label_medication) training pairs\n",
        "from collections import defaultdict, Counter\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "from scipy.stats import halfnorm\n",
        "\n",
        "# Flatten all codes\n",
        "all_codes = [code for visits in patients_visits.values() for _, code, _ in visits]\n",
        "code_freq = Counter(all_codes)\n",
        "total_codes = sum(code_freq.values())\n",
        "\n",
        "# Compute sampling probability\n",
        "downsample_probs = {code: min(1.0, 1.0 / np.sqrt(freq / total_codes)) for code, freq in code_freq.items()}\n",
        "\n",
        "def sample_context_window(std_weeks=40):\n",
        "    # Draw from a half-normal distribution (weeks), convert to timedelta\n",
        "    weeks = halfnorm.rvs(scale=std_weeks)\n",
        "    return timedelta(weeks=int(weeks))\n",
        "\n",
        "def bin_by_2_months(events):\n",
        "    # Bin events into 2-month periods\n",
        "    binned = defaultdict(list)\n",
        "    for date, code in events:\n",
        "        bin_key = (date.year, date.month // 2)\n",
        "        binned[bin_key].append((date, code))\n",
        "    return binned\n",
        "\n",
        "skip_gram_pairs = []\n",
        "\n",
        "for patient_id, events in patients_visits.items():\n",
        "    # Separate medication events from context (diagnoses + procedures)\n",
        "    context_events = [(d, c) for d, c, t in events if t != 'medication']\n",
        "    med_events = [(d, c) for d, c, t in events if t == 'medication']\n",
        "\n",
        "    for med_date, med_code in med_events:\n",
        "        window = sample_context_window()\n",
        "        window_start = med_date - window\n",
        "\n",
        "        # Select context events within the window\n",
        "        context_in_window = [(d, c) for d, c in context_events if window_start <= d < med_date]\n",
        "\n",
        "        if not context_in_window:\n",
        "            continue\n",
        "\n",
        "        # Bin events by 2-month period\n",
        "        binned = bin_by_2_months(context_in_window)\n",
        "\n",
        "        sampled_context_codes = []\n",
        "        for bin_events in binned.values():\n",
        "            sampled_date, sampled_code = random.choice(bin_events)\n",
        "\n",
        "            # Downsampling based on frequency\n",
        "            if random.random() < downsample_probs.get(sampled_code, 1.0):\n",
        "                sampled_context_codes.append(sampled_code)\n",
        "\n",
        "        for context_code in sampled_context_codes:\n",
        "            skip_gram_pairs.append((str(context_code), str(med_code)))\n",
        "\n",
        "print(skip_gram_pairs[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6N8wdskLrEs",
        "outputId": "7941d475-2c42-401b-a44b-ea497d37b0fa"
      },
      "outputs": [],
      "source": [
        "# Get all unique codes from the skip-gram pairs\n",
        "unique_codes = set()\n",
        "for h, t in skip_gram_pairs:\n",
        "    unique_codes.add(h)\n",
        "    unique_codes.add(t)\n",
        "\n",
        "# Create mappings\n",
        "code_to_index = {code: idx for idx, code in enumerate(sorted(unique_codes))}\n",
        "index_to_code = {idx: code for code, idx in code_to_index.items()}\n",
        "\n",
        "vocab_size = len(code_to_index)\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4HeJHLhN4E4",
        "outputId": "964cb496-0aa9-4210-da30-680c239f2e4a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "31IXeiaHN73V"
      },
      "outputs": [],
      "source": [
        "#load skip-grams using dataloader\n",
        "encoded_pairs = [(code_to_index[h], code_to_index[t]) for h, t in skip_gram_pairs\n",
        "                 if h in code_to_index and t in code_to_index]\n",
        "\n",
        "class SkipGramDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context_idx, target_idx = self.pairs[idx]\n",
        "        return torch.tensor(context_idx, dtype=torch.long), torch.tensor(target_idx, dtype=torch.long)\n",
        "\n",
        "dataset = SkipGramDataset(encoded_pairs)\n",
        "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
        "\n",
        "#use skip_gram_pairs to create embeddings\n",
        "class SkipGramDataset(Dataset):\n",
        "    def __init__(self, skip_gram_pairs, code_to_index):\n",
        "        self.pairs = skip_gram_pairs\n",
        "        self.code_to_index = code_to_index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context_code, target_code = self.pairs[idx]\n",
        "        return torch.tensor(self.code_to_index[context_code], dtype=torch.long), \\\n",
        "               torch.tensor(self.code_to_index[target_code], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "65GDZsqZBpql"
      },
      "outputs": [],
      "source": [
        "#setup word2vec model\n",
        "class IndicationEmbeddingModel(nn.Module):\n",
        "    def __init__(self, vocab_size=len(code_to_index), embed_dim=50, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.output_weights = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, context_idxs):\n",
        "        x = self.embeddings(context_idxs)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.output_weights(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dowUUA7qBsuN",
        "outputId": "0123a6fe-529f-417f-ee80-fa28067b7856"
      },
      "outputs": [],
      "source": [
        "#train model\n",
        "epochs = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = IndicationEmbeddingModel(vocab_size).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "losses = []\n",
        "epoch_times = []\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    epoch_start_time = time.time()\n",
        "    for context_batch, target_batch in dataloader:\n",
        "        context_batch, target_batch = context_batch.to(device), target_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(context_batch)\n",
        "        loss = criterion(logits, target_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    losses.append(total_loss)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - epoch_start_time\n",
        "    epoch_times.append(epoch_time)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "print(f\"Average epoch run time: {np.mean(epoch_times):.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "gz3nSNB7kOU_",
        "outputId": "8217a8ba-ec74-4ed0-b4f1-a557fd4183cf"
      },
      "outputs": [],
      "source": [
        "#plot training loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(losses) + 1), losses)\n",
        "plt.title('Training Loss per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "YFeOKCIfqfY3"
      },
      "outputs": [],
      "source": [
        "# Normalize embeddings to unit vectors\n",
        "raw_embeddings = model.embeddings.weight.data\n",
        "normalized_embeddings = F.normalize(raw_embeddings, p=2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "unWwphrfrIjf",
        "outputId": "fb261d10-7451-46b3-d048-7cdb302fc957"
      },
      "outputs": [],
      "source": [
        "#plot embeddings\n",
        "index_to_code = {idx: code for code, idx in code_to_index.items()}\n",
        "\n",
        "code_type_dict = {}\n",
        "\n",
        "for visits in patients_visits.values():\n",
        "    for _, code, code_type in visits:\n",
        "        code_str = str(code)\n",
        "        if code_str not in code_type_dict:\n",
        "            code_type_dict[code_str] = code_type\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "embeddings_2d = tsne.fit_transform(normalized_embeddings)\n",
        "\n",
        "type_colors = {\n",
        "    'diagnosis': 'tab:blue',\n",
        "    'medication': 'tab:green',\n",
        "    'procedure': 'tab:red'\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "sample_indices = np.random.choice(len(embeddings_2d), size=100, replace=False)\n",
        "\n",
        "for idx in sample_indices:\n",
        "    x, y = embeddings_2d[idx]\n",
        "    code = index_to_code[idx]\n",
        "    code_type = code_type_dict.get(code, 'unknown')\n",
        "    color = type_colors.get(code_type, 'gray')\n",
        "    plt.scatter(x, y, color=color, s=40, alpha=0.6)\n",
        "    plt.text(x + 0.2, y, code, fontsize=8)\n",
        "\n",
        "for label, color in type_colors.items():\n",
        "    plt.scatter([], [], c=color, label=label)\n",
        "plt.legend()\n",
        "plt.title(\"Visualization of Indication Embeddings\")\n",
        "plt.xlabel(\"t-SNE Dim 1\")\n",
        "plt.ylabel(\"t-SNE Dim 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "2GIeOdz1XqJy"
      },
      "outputs": [],
      "source": [
        "#compare indication embeddings to MEDI dataset\n",
        "medi_df = pd.read_csv('data/MEDI-2.csv')\n",
        "medi_hps = pd.read_csv('data/MEDI-2_HPS.csv')\n",
        "\n",
        "medi_df = medi_df.rename(columns={'RXCUI': 'rxnorm_code', 'CODE' : 'ICD10'})\n",
        "medi_df['rxnorm_code'] = medi_df['rxnorm_code'].astype(str)\n",
        "medi_df['ICD10'] = medi_df['ICD10'].astype(str)\n",
        "\n",
        "medi_hps = medi_hps.rename(columns={'RXCUI': 'rxnorm_code', 'CODE' : 'ICD10'})\n",
        "medi_hps['rxnorm_code'] = medi_hps['rxnorm_code'].astype(str)\n",
        "medi_hps['ICD10'] = medi_hps['ICD10'].astype(str)\n",
        "\n",
        "#filter out rows where VOCABULARY != ICD10CM\n",
        "medi_df = medi_df[medi_df['VOCABULARY'] == 'ICD10CM']\n",
        "medi_hps = medi_hps[medi_hps['VOCABULARY'] == 'ICD10CM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61BV3zMFbNKa",
        "outputId": "f698b9d0-b8c4-4c69-e9d2-c8c92462ed67"
      },
      "outputs": [],
      "source": [
        "positive_pairs = set([tuple(x) for x in medi_hps[['rxnorm_code', 'ICD10']].values])\n",
        "drug_codes = set(medi_df['rxnorm_code'])\n",
        "diagnosis_codes = set(medi_df['ICD10'])\n",
        "\n",
        "all_possible_pairs = [(d, icd) for d in drug_codes for icd in diagnosis_codes]\n",
        "negative_pairs = [pair for pair in all_possible_pairs if pair not in positive_pairs]\n",
        "\n",
        "#sample negatives for balance\n",
        "random.seed(42)\n",
        "negative_pairs = random.sample(negative_pairs, k=750000)\n",
        "print(f\"Positives: {len(positive_pairs)} | Negatives: {len(negative_pairs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8aWwChWeQOT",
        "outputId": "aa6e8152-91f9-4d34-c905-2537bfb798bf"
      },
      "outputs": [],
      "source": [
        "#compute cosine similarity\n",
        "emb_matrix = normalized_embeddings.numpy()\n",
        "def get_similarity(code1, code2):\n",
        "    idx1 = code_to_index.get(code1)\n",
        "    idx2 = code_to_index.get(code2)\n",
        "    if idx1 is None or idx2 is None:\n",
        "        return None\n",
        "    return np.dot(emb_matrix[idx1], emb_matrix[idx2])\n",
        "\n",
        "# Score pairs\n",
        "pairs = list(positive_pairs) + list(negative_pairs)\n",
        "labels = [1]*len(positive_pairs) + [0]*len(negative_pairs)\n",
        "\n",
        "scores = []\n",
        "for drug, diagnosis in tqdm(pairs):\n",
        "    sim = get_similarity(drug, diagnosis)\n",
        "    if sim is not None:\n",
        "        scores.append(sim)\n",
        "    else:\n",
        "        scores.append(0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "QD_w_x58eZ5T",
        "outputId": "2b0c2ada-292a-4ed4-f338-dc30fb32b285"
      },
      "outputs": [],
      "source": [
        "#plot roc curve\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(labels, scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, label=f'Embedding Similarity (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve: Reproduced Indication Embedding Similarity')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQq2j1-0oF6A"
      },
      "source": [
        "The code in the following section borrows heavily from the author of the original paper, who made their script available on Github."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "bcn0tyUks7AH"
      },
      "outputs": [],
      "source": [
        "evemb = pd.read_table('data/indication_embedding.csv', index_col=0)\n",
        "voc = pd.read_table('data/indications_vocab.tsv', sep=\"\\t\",index_col=0)\n",
        "\n",
        "#drug to theraputic group mapping\n",
        "(g2thrgrds, thrgrds) = pickle.load(open(\"data/g2thrgrds.pkl\",'rb'))\n",
        "(icd2ccs, ccsdo) = pickle.load(open(\"data/icd2ccs.pkl\", 'rb'))\n",
        "icd2ccs_dict = dict(zip(*tuple((icd2ccs.index, icd2ccs['ccs']))))\n",
        "ccs2icd = {p:[i for i,pc in icd2ccs_dict.items() if p in pc] for p in set(icd2ccs_dict.values())}\n",
        "\n",
        "icd2phe = pickle.load(open(\"data/icd2phe.03.18.pkl\",'rb'))\n",
        "phe2icd = {p:[i for i,pc in icd2phe.items() if p in pc] for p in set(icd2phe.values())}\n",
        "\n",
        "cut = 20000\n",
        "## filter to keep Dx and Rx that are in more than 20000 patients\n",
        "dxvoc = voc.loc[(voc['type']=='dx') & (voc['id']>0) & (voc['ct'] > cut),:]\n",
        "rxvoc = voc.loc[(voc['type']=='rx') & (voc['id']>0) & (voc['ct'] > cut),:]\n",
        "\n",
        "rxemb = evemb.loc[rxvoc['code'],:]\n",
        "dxemb = evemb.loc[dxvoc['code'],:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "5JQbhI2xDmDD",
        "outputId": "a3deb544-840e-40aa-85cc-b07606f15bfd"
      },
      "outputs": [],
      "source": [
        "rxdotdx_sel = rxemb.dot(dxemb.transpose()).transpose()\n",
        "\n",
        "hps = pickle.load(open(\"data/MEDI_01212013_HPS.pkl\",'rb'))\n",
        "medi = pickle.load(open(\"data/MEDI_01212013.pkl\",'rb'))\n",
        "\n",
        "isind = []\n",
        "for row in rxdotdx_sel.index:\n",
        "    isind.append(rxdotdx_sel.columns.isin(hps[row]))\n",
        "isind = pd.DataFrame(isind,index=rxdotdx_sel.index,columns = rxdotdx_sel.columns)\n",
        "\n",
        "## filter to ICD and Drug that have at least one indication relationship in the High Precision Set\n",
        "## after removing those drugs that are nonspecific (prescribed for more than 2% of diseases)\n",
        "selcol =(isind.sum(axis=0) >= 1)\n",
        "selrow =(isind.sum(axis=1) >= 1)\n",
        "\n",
        "isind = isind.loc[selrow,selcol]\n",
        "rxdotdx_sel = rxdotdx_sel.loc[selrow,selcol]\n",
        "\n",
        "### full set -- \"low precision\"\n",
        "mediisind = []\n",
        "for row in rxdotdx_sel.index:\n",
        "    mediisind.append(rxdotdx_sel.columns.isin(medi[row]))\n",
        "mediisind = pd.DataFrame(mediisind,index=rxdotdx_sel.index,columns = rxdotdx_sel.columns)\n",
        "\n",
        "### negative = not in High precision set OR in full set of indications\n",
        "neg = rxdotdx_sel.values.reshape(-1,1)[(~isind & ~mediisind).values.reshape(-1,1)==True]\n",
        "\n",
        "### positive = high precision set\n",
        "pos = rxdotdx_sel.values.reshape(-1,1)[isind.values.reshape(-1,1)==True]\n",
        "original_roc = roc_auc_score(np.append(np.ones(pos.shape),np.zeros(neg.shape)), np.append(pos,neg))\n",
        "print(\"ROC AUC: {:1.2f}\".format(roc_auc_score(np.append(np.ones(pos.shape),np.zeros(neg.shape)), np.append(pos,neg))))\n",
        "\n",
        "y_scores = np.append(pos, neg)\n",
        "y_true = np.append(np.ones(pos.shape), np.zeros(neg.shape))\n",
        "\n",
        "# Compute ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, label=f'ROC AUC = {original_roc:.2f}', color='darkblue', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve: Original Indication Embedding Similaririty')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
